docs_deploy: &docs
  docker:
    - image: node:8.10.0
  working_directory: /tmp/gh-pages
  steps:
    - run:
        name: Check whether this is the original repo
        command: |
          if [[ "$CIRCLE_PROJECT_USERNAME" != "poldracklab" ]]; then
              echo "Not in poldracklab/sdcflows - skipping docs deploy."
              circleci step halt
          fi
    - add_ssh_keys:
        fingerprints:
          - "46:48:1e:6d:00:0e:f2:f8:e5:aa:b9:aa:da:eb:59:4e"
    - run:
        name: Install gh-pages tool
        command: |
          npm install -g --silent gh-pages@2.0.1
    - checkout
    - run:
        name: Set git settings
        command: |
          git config user.email "crn.poldracklab@gmail.com"
          git config user.name "Documentation Push"
    - attach_workspace:
        at: docs/_build
    - run:
        name: Disable jekyll builds
        command: touch docs/_build/html/.nojekyll
    - run:
        name: Deploy docs to gh-pages branch
        command: gh-pages --dotfiles --message "doc(update) [skip ci]" --dist docs/_build/html

version: 2
jobs:
  cache_test_data:
    docker:
      - image: python:3.7.4
    working_directory: /tmp/data
    environment:
      - TEMPLATEFLOW_HOME: /tmp/templateflow
    steps:
      - restore_cache:
          keys:
            - env-v1-{{ .Branch }}-
            - env-v1-master-
            - env-v1-
      - restore_cache:
          keys:
            - data-v2-{{ .Branch }}-
            - data-v2-master-
            - data-v2-

      - run:
          name: Setup git-annex
          command: |
            if [[ ! -d /usr/lib/git-annex.linux ]]; then
              wget -O- http://neuro.debian.net/lists/trusty.us-ca.full | sudo tee /etc/apt/sources.list.d/neurodebian.sources.list
              apt-key adv --recv-keys --keyserver hkp://pool.sks-keyservers.net:80 0xA5D32F012649A5A9
              apt update && sudo apt-get install -y --no-install-recommends git-annex-standalone
            fi
            git config --global user.name 'CRN'
            git config --global user.email 'crn.poldracklab@gmail.com'

      - run:
          name: Setup DataLad & TemplateFlow
          command: |
            python -m pip install --no-cache-dir -U pip
            python -m pip install --no-cache-dir -U datalad
            python -m pip install --no-cache-dir -U templateflow
            python -c "from templateflow import api as tfapi; \
                       tfapi.get('MNI152NLin2009cAsym', resolution=2, desc='brain', suffix='mask'); \
                       tfapi.get('MNI152NLin2009cAsym', resolution=2, desc='fMRIPrep', suffix='boldref');"

      - save_cache:
         key: env-v1-{{ .Branch }}-{{ .BuildNum }}
         paths:
            - /tmp/cache/git-annex-standalone.tar.gz
            - /usr/local/lib/python3.7/site-packages
            - /usr/bin/git-annex
            - /usr/bin/git-annex-shell
            - /usr/lib/git-annex.linux

      - run:
          name: Install ds001600
          command: |
            datalad install https://github.com/OpenNeuroDatasets/ds001600.git
            datalad update --merge ds001600/
            datalad get -r ds001600/*
      - run:
          name: Get testdata
          command: |
            if [[ ! -d /tmp/data/testdata ]]; then
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                  -O testdata.zip "https://files.osf.io/v1/resources/9sy2a/providers/osfstorage/5d44b940bcd6d900198ed6be/?zip="
              unzip testdata.zip -d /tmp/data/testdata
            fi
      - save_cache:
         key: data-v2-{{ .Branch }}-{{ .BuildNum }}
         paths:
            - /tmp/data
            - /tmp/templateflow

      - restore_cache:
          keys:
            - freesurfer-v1-{{ .Branch }}-
            - freesurfer-v1-master-
            - freesurfer-v1-
      - run:
          name: Pull FreeSurfer down
          command: |
            if [[ ! -d /tmp/freesurfer ]]; then
              curl -sSL https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.1/freesurfer-Linux-centos6_x86_64-stable-pub-v6.0.1.tar.gz | tar zxv --no-same-owner -C /tmp \
                   --exclude='freesurfer/diffusion' \
                   --exclude='freesurfer/docs' \
                   --exclude='freesurfer/fsfast' \
                   --exclude='freesurfer/lib/cuda' \
                   --exclude='freesurfer/lib/qt' \
                   --exclude='freesurfer/matlab' \
                   --exclude='freesurfer/mni/share/man' \
                   --exclude='freesurfer/subjects/fsaverage_sym' \
                   --exclude='freesurfer/subjects/fsaverage3' \
                   --exclude='freesurfer/subjects/fsaverage4' \
                   --exclude='freesurfer/subjects/cvs_avg35' \
                   --exclude='freesurfer/subjects/cvs_avg35_inMNI152' \
                   --exclude='freesurfer/subjects/bert' \
                   --exclude='freesurfer/subjects/lh.EC_average' \
                   --exclude='freesurfer/subjects/rh.EC_average' \
                   --exclude='freesurfer/subjects/sample-*.mgz' \
                   --exclude='freesurfer/subjects/V1_average' \
                   --exclude='freesurfer/trctrain'
              echo "b2VzdGViYW5Ac3RhbmZvcmQuZWR1CjMwNzU2CiAqQ1MzYkJ5VXMxdTVNCiBGU2kvUGJsejJxR1V3Cg==" | base64 -d > /tmp/freesurfer/license.txt
            fi
      - save_cache:
         key: freesurfer-v1-{{ .Branch }}-{{ .BuildNum }}
         paths:
            - /tmp/freesurfer

  build_n_pytest:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/tests
    environment:
      TZ: "/usr/share/zoneinfo/America/Los_Angeles"
    steps:
      - restore_cache:
          keys:
            - build-v2-{{ .Branch }}-{{ epoch }}
            - build-v2-{{ .Branch }}-
            - build-v2-master-
            - build-v2-
          paths:
            - /tmp/docker
      - run:
          name: Set-up a Docker registry
          command: |
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images
          command: |
            set +e
            docker pull localhost:5000/ubuntu
            success=$?
            set -e
            if [[ "$success" = "0" ]]; then
                echo "Pulling from local registry"
                docker tag localhost:5000/ubuntu ubuntu:xenial-20191010
                docker pull localhost:5000/sdcflows
                docker tag localhost:5000/sdcflows poldracklab/sdcflows:latest
                docker tag localhost:5000/sdcflows poldracklab/sdcflows
            else
                echo "Pulling from Docker Hub"
                docker pull ubuntu:xenial-20191010
                docker tag ubuntu:xenial-20191010 localhost:5000/ubuntu
                docker push localhost:5000/ubuntu
                docker pull poldracklab/sdcflows:latest
            fi
      - checkout:
          path: /tmp/src/sdcflows
      - run:
          name: Build Docker image
          no_output_timeout: 60m
          command: |
            cd /tmp/src/sdcflows
            export PY3=$(pyenv versions | grep '3\.' |
                         sed -e 's/.* 3\./3./' -e 's/ .*//')
            pyenv local $PY3
            # Get version, update files.
            THISVERSION=$( python3 get_version.py )
            if [[ ${THISVERSION:0:1} == "0" ]] ; then
              echo "WARNING: latest git tag could not be found"
              echo "Please, make sure you fetch all tags from upstream with"
              echo "the command ``git fetch --tags --verbose`` and push"
              echo "them to your fork with ``git push origin --tags``"
            fi
            # Build docker image
            e=1 && for i in {1..5}; do
              docker build --rm \
                --cache-from=poldracklab/sdcflows \
                -t poldracklab/sdcflows:latest \
                --build-arg BUILD_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ"` \
                --build-arg VCS_REF=`git rev-parse --short HEAD` \
                --build-arg VERSION="${CIRCLE_TAG:-$THISVERSION}" . \
              && e=0 && break || sleep 15
            done && [ "$e" -eq "0" ]
      - run:
          name: Docker push to local registry
          no_output_timeout: 40m
          command: |
            docker tag poldracklab/sdcflows:latest localhost:5000/sdcflows
            docker push localhost:5000/sdcflows
      - run:
          name: Docker registry garbage collection
          command: |
            docker exec -it registry /bin/registry garbage-collect --delete-untagged \
                /etc/docker/registry/config.yml
      - save_cache:
         key: build-v2-{{ .Branch }}-{{ epoch }}
         paths:
            - /tmp/docker

      - restore_cache:
          keys:
            - freesurfer-v1-{{ .Branch }}-
            - freesurfer-v1-master-
            - freesurfer-v1-
      - restore_cache:
          keys:
            - data-v2-{{ .Branch }}-
            - data-v2-master-
            - data-v2-
      - restore_cache:
          keys:
            - workdir-v2-{{ .Branch }}-
            - workdir-v2-master-
            - workdir-v2-
      - run:
          name: Refreshing cached intermediate results
          command: |
            cd /tmp/src/sdcflows
            COMMIT_MSG=$( git log --format=oneline -n 1 $CIRCLE_SHA1 )
            set +e
            do_refresh="$( echo "${COMMIT_MSG}" | grep -i -E '\[refresh[ _]?cache\]' )"
            set -e
            if [[ "x${do_refresh}" = "x" ]]; then
              echo "Did not refresh the workdir."
            else
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                  -O /tmp/data/workdir.tar.gz "https://files.osf.io/v1/resources/9sy2a/providers/osfstorage/5dcabd60a1cd9e000c751b3c"
              rm -rf /tmp/work
              mkdir -p /tmp/work
              pushd /tmp/work
              tar xzfv /tmp/data/workdir.tar.gz --strip 1
              popd
            fi

            wipe_dir=$( echo "${COMMIT_MSG}" | sed -n 's/.*\[wipe \([a-zA-Z0-9_\*]*\)\].*/\1/p' )
            if [[ "x${wipe_dir}" != "x" ]]; then
              path=/tmp/work/${wipe_dir}
              echo "Found tag [wipe ${wipe_dir}] - clearing up $path ..."
              rm -rf ${path}
            fi
      - run:
          name: Run tests
          no_output_timeout: 2h
          command: |
            mkdir -p /tmp/work
            docker run -it --rm -e TEST_DATA_HOME=/data/ -e TEST_OUTPUT_DIR=/out \
                   -v /tmp/freesurfer:/opt/freesurfer:ro -e FS_LICENSE=/opt/freesurfer/license.txt \
                   -v /tmp/work:/work -e TEST_WORK_DIR=/work \
                   -v /tmp/templateflow:/home/sdcflows/.cache/templateflow \
                   -v /tmp/data:/data:ro -v /tmp/src:/src -v /tmp/tests:/out \
                   -w /work poldracklab/sdcflows:latest \
                   pytest -v --junit-xml=/out/pytest.xml /src/sdcflows/sdcflows
      - save_cache:
         key: workdir-v2-{{ .Branch }}-{{ .BuildNum }}
         paths:
            - /tmp/work
      - store_artifacts:
          path: /tmp/tests
      - store_test_results:
          path: /tmp/tests

  build_docs:
    docker:
      - image: python:3.7.4
    working_directory: /tmp/gh-pages
    environment:
      - FSLOUTPUTTYPE: NIFTI
      - SUBJECTS_DIR: /tmp/subjects
    steps:
      - checkout
      - run:
          name: Create subjects folder
          command: mkdir -p $SUBJECTS_DIR
      - run:
          name: Install Graphviz
          command: apt update && apt -y install graphviz
      - run:
          name: Install deps
          command: pip install --no-cache-dir -r docs/requirements.txt
      - run:
          name: Build only this commit
          command: make -C docs SPHINXOPTS="-W" BUILDDIR="_build/no_version_html" html
      - store_artifacts:
          path: ./docs/_build/no_version_html
      - run:
          name: Stop or generate versioned docs?
          command: |
            set +e
            force_versioned="$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[docs?[ _]?versions?\]' )"
            set -e
            if [[ "x${CIRCLE_TAG}" = "x" && "${CIRCLE_BRANCH}" != "master" && "x${force_versioned}" = "x" ]]; then
              echo "Not a tag or master branch - skipping versioned docs."
              circleci step halt
            fi
      - restore_cache:
          keys:
            - docs-v1-{{ .Branch }}-{{ .Revision }}
            - docs-v1-{{ .Branch }}-
            - docs-v1-master
            - docs-v1-
          paths:
            - ./docs/_build/_html
      - run:
          name: Generate Versioned Docs
          command: make -f ./docs/Makefile versioned CURBRANCH=${CIRCLE_TAG:-$CIRCLE_BRANCH}
      - save_cache:
          key: docs-v1-{{ .Branch }}-{{ .Revision }}
          paths:
            - ./docs/_build/_html
      - persist_to_workspace:
          root: docs/_build
          paths: html
      - store_artifacts:
          path: ./docs/_build/html

  deploy_docker:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/src/
    steps:
      - restore_cache:
          keys:
            - build-v2-{{ .Branch }}-{{ epoch }}
            - build-v2-{{ .Branch }}-
            - build-v2-master-
            - build-v2-
          paths:
            - /tmp/docker
      - run:
          name: Set-up a Docker registry
          command: |
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images from local registry
          command: |
            docker pull localhost:5000/sdcflows
            docker tag localhost:5000/sdcflows poldracklab/sdcflows:latest
      - run:
          name: Deploy to Docker Hub
          no_output_timeout: 40m
          command: |
            if [[ -n "$DOCKER_PASS" ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PASS
              docker push poldracklab/sdcflows:latest
              docker tag poldracklab/sdcflows poldracklab/sdcflows:$CIRCLE_TAG
              docker push poldracklab/sdcflows:$CIRCLE_TAG
            fi

  test_package:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/src/sdcflows
    steps:
      - checkout
      - run:
          name: Setup Python environment with virtualenvs
          command: |
            pyenv global 3.5.2
            python3 -m pip install --upgrade virtualenv
      - run:
          name: Prepare build environment
          command: |
            virtualenv --python=python3 /tmp/build
            source /tmp/build/bin/activate
            python3 -m pip install "setuptools>=30.3.0" "pip>=10.0.1" twine docutils
      - run:
          name: Prepare install environment
          command: |
            virtualenv --python=python3 /tmp/install
            source /tmp/install/bin/activate
            python3 -m pip install "setuptools>=30.3.0" "pip>=10.0.1"
      - run:
          name: Build SDCflows in build environment
          command: |
            source /tmp/build/bin/activate
            python setup.py sdist
      - store_artifacts:
          path: /tmp/src/sdcflows/dist
      - run:
          name: Check sdist package in build environment
          command: |
            source /tmp/build/bin/activate
            twine check dist/sdcflows*.tar.gz
      - run:
          name: Install sdist package into install environment and check version
          command: |
            source /tmp/install/bin/activate
            THISVERSION=$( python get_version.py )
            THISVERSION=${CIRCLE_TAG:-$THISVERSION}
            pip install dist/sdcflows*.tar.gz
            which sdcflows | grep install\\/bin
            INSTALLED_VERSION=$(sdcflows --version)
            INSTALLED_VERSION=${INSTALLED_VERSION%$'\r'}
            INSTALLED_VERSION=${INSTALLED_VERSION#*"sdcflows v"}
            echo "VERSION: \"$THISVERSION\""
            echo "INSTALLED: \"$INSTALLED_VERSION\""
            test "$INSTALLED_VERSION" = "v$THISVERSION"

  deploy_pypi:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/src/sdcflows
    steps:
      - checkout
      - run:
          name: Setup Python environment with virtualenvs
          command: |
            pyenv global 3.5.2
            python3 -m pip install --upgrade virtualenv
      - run:
          name: Prepare build environment
          command: |
            virtualenv --python=python3 /tmp/build
            source /tmp/build/bin/activate
            python3 -m pip install "setuptools>=30.3.0" "pip>=10.0.1" twine docutils
      - run:
          name: Prepare install environment
          command: |
            virtualenv --python=python3 /tmp/install
            source /tmp/install/bin/activate
            python3 -m pip install "setuptools>=30.3.0" "pip>=10.0.1"
      - run:
          name: Build SDCflows in build environment
          command: |
            source /tmp/build/bin/activate
            python setup.py sdist
      - store_artifacts:
          path: /tmp/src/sdcflows/dist
      - run:
          name: Check sdist package in build environment
          command: |
            source /tmp/build/bin/activate
            twine check dist/sdcflows*.tar.gz
      - run:
          name: Install sdist package into install environment and check version
          command: |
            source /tmp/install/bin/activate
            THISVERSION=$( python get_version.py )
            THISVERSION=${CIRCLE_TAG:-$THISVERSION}
            pip install dist/sdcflows*.tar.gz
            which sdcflows | grep install\\/bin
            INSTALLED_VERSION=$(sdcflows --version)
            INSTALLED_VERSION=${INSTALLED_VERSION%$'\r'}
            INSTALLED_VERSION=${INSTALLED_VERSION#*"sdcflows v"}
            echo "VERSION: \"$THISVERSION\""
            echo "INSTALLED: \"$INSTALLED_VERSION\""
            test "$INSTALLED_VERSION" = "v$THISVERSION"
      - run:
          name: Upload packages to PyPI
          command: |
            source /tmp/build/bin/activate
            twine upload dist/sdcflows*

  deploy_docs_tag:
    <<: *docs

  deploy_docs_master:
    <<: *docs

workflows:
  version: 2
  build_deploy:
    jobs:
      - cache_test_data:
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - build_n_pytest:
          requires:
            - cache_test_data
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - test_package:
          filters:
            branches:
              ignore:
                - /docs?\/.*/
                - /tests?\/.*/
            tags:
              only: /.*/

      - deploy_pypi:
          requires:
            - build_docs
            - test_package
            - build_n_pytest
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

      - deploy_docker:
          requires:
            - deploy_pypi
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

      - build_docs:
          filters:
            branches:
              ignore:
                - /tests?\/.*/
            tags:
              only: /.*/

      - deploy_docs_master:
          requires:
            - build_n_pytest
            - test_package
            - build_docs
          filters:
            branches:
              only: /master/
            tags:
              ignore: /.*/

      - deploy_docs_tag:
          requires:
            - deploy_docker
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
