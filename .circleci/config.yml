docs_deploy: &docs
  docker:
    - image: node:8.10.0
  working_directory: /tmp/gh-pages
  steps:
    - run:
        name: Check whether this is the original repo
        command: |
          if [[ "$CIRCLE_PROJECT_USERNAME" != "nipreps" ]]; then
              echo "Not in nipreps/sdcflows - skipping docs deploy."
              circleci step halt
          fi
    - add_ssh_keys:
        fingerprints:
          - "46:48:1e:6d:00:0e:f2:f8:e5:aa:b9:aa:da:eb:59:4e"
    - run:
        name: Install gh-pages tool
        command: |
          npm install -g --silent gh-pages@2.0.1
    - checkout
    - run:
        name: Set git settings
        command: |
          git config user.email "nipreps@gmail.com"
          git config user.name "Documentation Push"
    - attach_workspace:
        at: docs/_build
    - run:
        name: Disable jekyll builds
        command: touch docs/_build/html/.nojekyll
    - run:
        name: Deploy docs to gh-pages branch
        command: gh-pages --dotfiles --message "doc(update) [skip ci]" --dist docs/_build/html

version: 2
jobs:
  cache_test_data:
    docker:
      - image: python:3.7.4
    working_directory: /tmp/data
    environment:
      - TEMPLATEFLOW_HOME: /tmp/templateflow
    steps:
      - restore_cache:
          keys:
            - env-v2-{{ .Branch }}-
            - env-v2-master-
            - env-v2-
      - restore_cache:
          keys:
            - data-v3-{{ .Branch }}-
            - data-v3-master-
            - data-v3-

      - run:
          name: Setup git-annex
          command: |
            if [[ ! -d /usr/lib/git-annex.linux ]]; then
              wget -O- http://neuro.debian.net/lists/focal.us-ca.full | tee /etc/apt/sources.list.d/neurodebian.sources.list
              apt-key adv --recv-keys --keyserver hkp://pool.sks-keyservers.net:80 0xA5D32F012649A5A9
              apt update && apt-get install -y --no-install-recommends git-annex-standalone
            fi
            git config --global user.name 'NiPreps Bot'
            git config --global user.email 'nipreps@gmail.com'

      - run:
          name: Setup DataLad & TemplateFlow
          command: |
            python -m pip install --no-cache-dir -U pip
            python -m pip install --no-cache-dir -U datalad datalad-osf
            python -m pip install --no-cache-dir -U templateflow
            python -c "from templateflow import api as tfapi; \
                       tfapi.get('MNI152NLin2009cAsym', resolution=2, desc='brain', suffix='mask'); \
                       tfapi.get('MNI152NLin2009cAsym', resolution=2, desc='fMRIPrep', suffix='boldref');"

      - save_cache:
          key: env-v2-{{ .Branch }}-{{ .BuildNum }}
          paths:
            - /tmp/cache/git-annex-standalone.tar.gz
            - /usr/local/bin
            - /usr/local/lib/python3.7/site-packages
            - /usr/bin/git-annex
            - /usr/bin/git-annex-shell
            - /usr/lib/git-annex.linux

      - run:
          name: Install ds001600
          command: |
            datalad install https://github.com/OpenNeuroDatasets/ds001600.git
            datalad update --merge -d ds001600/
            datalad get -r -d ds001600/

      - run:
          name: Install HCP/sub-101006
          command: |
            datalad install -r https://github.com/nipreps-data/HCP101006.git
            datalad update -r --merge -d HCP101006/
            datalad get -r -d HCP101006

      - run:
          name: Install ds001771
          command: |
            datalad install -r https://github.com/nipreps-data/ds001771.git
            datalad update --merge -d ds001771/
            datalad get -r -d ds001771/ ds001771/sub-36/fmap/*

      - save_cache:
          key: data-v3-{{ .Branch }}-{{ .BuildNum }}
          paths:
            - /tmp/data
            - /tmp/templateflow

      - restore_cache:
          keys:
            - freesurfer-v1-{{ .BuildNum }}
            - freesurfer-v1-
      - run:
          name: Pull FreeSurfer down
          command: |
            if [[ ! -d /tmp/freesurfer ]]; then
              curl -sSL https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.1/freesurfer-Linux-centos6_x86_64-stable-pub-v6.0.1.tar.gz | tar zxv --no-same-owner -C /tmp \
                   --exclude='freesurfer/diffusion' \
                   --exclude='freesurfer/docs' \
                   --exclude='freesurfer/fsfast' \
                   --exclude='freesurfer/lib/cuda' \
                   --exclude='freesurfer/lib/qt' \
                   --exclude='freesurfer/matlab' \
                   --exclude='freesurfer/mni/share/man' \
                   --exclude='freesurfer/subjects/fsaverage_sym' \
                   --exclude='freesurfer/subjects/fsaverage3' \
                   --exclude='freesurfer/subjects/fsaverage4' \
                   --exclude='freesurfer/subjects/cvs_avg35' \
                   --exclude='freesurfer/subjects/cvs_avg35_inMNI152' \
                   --exclude='freesurfer/subjects/bert' \
                   --exclude='freesurfer/subjects/lh.EC_average' \
                   --exclude='freesurfer/subjects/rh.EC_average' \
                   --exclude='freesurfer/subjects/sample-*.mgz' \
                   --exclude='freesurfer/subjects/V1_average' \
                   --exclude='freesurfer/trctrain'
              echo "b2VzdGViYW5Ac3RhbmZvcmQuZWR1CjMwNzU2CiAqQ1MzYkJ5VXMxdTVNCiBGU2kvUGJsejJxR1V3Cg==" | base64 -d > /tmp/freesurfer/license.txt
            else
              echo "FreeSurfer was cached."
              circleci step halt
            fi
      - save_cache:
          key: freesurfer-v1-{{ .BuildNum }}
          paths:
            - /tmp/freesurfer

  build_n_pytest:
    machine:
      image: circleci/classic:201808-01
    working_directory: /tmp/tests
    environment:
      TZ: "/usr/share/zoneinfo/America/Los_Angeles"
    steps:
      - restore_cache:
          keys:
            - build-v2-{{ .Branch }}-{{ epoch }}
            - build-v2-{{ .Branch }}-
            - build-v2-master-
            - build-v2-
          paths:
            - /tmp/docker
      - run:
          name: Set-up a Docker registry
          command: |
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images
          command: |
            set +e
            docker pull localhost:5000/ubuntu
            success=$?
            set -e
            if [[ "$success" = "0" ]]; then
                echo "Pulling from local registry"
                docker tag localhost:5000/ubuntu ubuntu:xenial-20191010
                docker pull localhost:5000/sdcflows
                docker tag localhost:5000/sdcflows nipreps/sdcflows:latest
                docker tag localhost:5000/sdcflows nipreps/sdcflows
            else
                echo "Pulling from Docker Hub"
                docker pull ubuntu:xenial-20191010
                docker tag ubuntu:xenial-20191010 localhost:5000/ubuntu
                docker push localhost:5000/ubuntu
                docker pull nipreps/sdcflows:latest
            fi
      - checkout:
          path: /tmp/src/sdcflows
      - run:
          name: Build Docker image
          no_output_timeout: 60m
          command: |
            cd /tmp/src/sdcflows
            pyenv local 3.7.0
            python3 -m pip install "setuptools ~= 42.0" "setuptools_scm[toml] >= 3.4" "pip>=10.0.1"

            # Get version, update files.
            THISVERSION=$( python3 setup.py --version )
            if [[ ${THISVERSION:0:1} == "0" ]] ; then
              echo "WARNING: latest git tag could not be found"
              echo "Please, make sure you fetch all tags from upstream with"
              echo "the command ``git fetch --tags --verbose`` and push"
              echo "them to your fork with ``git push origin --tags``"
            fi
            # Build docker image
            e=1 && for i in {1..5}; do
              docker build --rm \
                --cache-from=nipreps/sdcflows \
                -t nipreps/sdcflows:latest \
                --build-arg BUILD_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ"` \
                --build-arg VCS_REF=`git rev-parse --short HEAD` \
                --build-arg VERSION="${CIRCLE_TAG:-$THISVERSION}" . \
              && e=0 && break || sleep 15
            done && [ "$e" -eq "0" ]
            echo "${CIRCLE_TAG:-$THISVERSION}" >> /tmp/.local-version.txt
      - run:
          name: Docker push to local registry
          no_output_timeout: 40m
          command: |
            docker tag nipreps/sdcflows:latest localhost:5000/sdcflows
            docker push localhost:5000/sdcflows
      - run:
          name: Docker registry garbage collection
          command: |
            docker exec -it registry /bin/registry garbage-collect --delete-untagged \
                /etc/docker/registry/config.yml
      - save_cache:
          key: build-v2-{{ .Branch }}-{{ epoch }}
          paths:
            - /tmp/docker
      - run:
          name: Check version packaged in Docker image
          command: |
              docker run --rm -v /tmp:/tmp -v /tmp/src/sdcflows/.circleci/version.py:/usr/share/version.py \
                     --entrypoint=python nipreps/sdcflows /usr/share/version.py
              THISVERSION=$( head -n1 /tmp/.local-version.txt )
              INSTALLED_VERSION=$( head -n1 /tmp/.docker-version.txt )
              echo "VERSION: \"${THISVERSION}\""
              echo "INSTALLED: \"${INSTALLED_VERSION}\""
              test "${INSTALLED_VERSION}" = "${THISVERSION}"

      - restore_cache:
          keys:
            - freesurfer-v1-{{ .BuildNum }}
            - freesurfer-v1-
      - restore_cache:
          keys:
            - data-v3-{{ .Branch }}-
            - data-v3-master-
            - data-v3-
      - restore_cache:
          keys:
            - workdir-v2-{{ .Branch }}-
            - workdir-v2-master-
            - workdir-v2-
      - run:
          name: Refreshing cached intermediate results
          command: |
            cd /tmp/src/sdcflows
            COMMIT_MSG=$( git log --format=oneline -n 1 $CIRCLE_SHA1 )
            set +e
            do_refresh="$( echo "${COMMIT_MSG}" | grep -i -E '\[refresh[ _]?cache\]' )"
            set -e
            if [[ "x${do_refresh}" = "x" ]]; then
              echo "Did not refresh the workdir."
            else
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                  -O /tmp/data/workdir.tar.gz "https://files.osf.io/v1/resources/9sy2a/providers/osfstorage/5dcabd60a1cd9e000c751b3c"
              rm -rf /tmp/work
              mkdir -p /tmp/work
              pushd /tmp/work
              tar xzfv /tmp/data/workdir.tar.gz --strip 1
              popd
            fi

            wipe_dir=$( echo "${COMMIT_MSG}" | sed -n 's/.*\[wipe \([a-zA-Z0-9_\*]*\)\].*/\1/p' )
            if [[ "x${wipe_dir}" != "x" ]]; then
              path=/tmp/work/${wipe_dir}
              echo "Found tag [wipe ${wipe_dir}] - clearing up $path ..."
              rm -rf ${path}
            fi
      - run:
          name: Run tests
          no_output_timeout: 2h
          command: |
            mkdir -p /tmp/work
            docker run -it --rm -w /src/sdcflows \
                -e TEST_WORK_DIR=/work \
                -e TEST_DATA_HOME=/data \
                -e TEST_OUTPUT_DIR=/out \
                -e COVERAGE_FILE=/out/.coverage \
                -e FS_LICENSE=/opt/freesurfer/license.txt \
                -v /tmp/data:/data:ro \
                -v /tmp/src:/src \
                -v /tmp/tests:/out \
                -v /tmp/work:/work \
                -v /tmp/freesurfer:/opt/freesurfer:ro  \
                -v /tmp/templateflow:/home/sdcflows/.cache/templateflow \
                nipreps/sdcflows:latest \
                pytest -v --junit-xml=/out/pytest.xml \
                       --cov sdcflows --cov-report xml:/out/unittests.xml \
                       sdcflows/
      - save_cache:
          key: workdir-v2-{{ .Branch }}-{{ .BuildNum }}
          paths:
            - /tmp/work
      - store_artifacts:
          path: /tmp/tests
      - store_test_results:
          path: /tmp/tests

      - run:
          name: Submit unit test coverage
          command: |
            pyenv local 3.7.0
            python3 -m pip install codecov
            cd /tmp/src/sdcflows
            python3 -m codecov --file /tmp/tests/unittests.xml \
                --flags unittests -e CIRCLE_JOB

  build_docs:
    docker:
      - image: python:3.7.4
    working_directory: /tmp/gh-pages
    environment:
      - FSLOUTPUTTYPE: NIFTI
      - SUBJECTS_DIR: /tmp/subjects
    steps:
      - checkout
      - run:
          name: Create subjects folder
          command: mkdir -p $SUBJECTS_DIR
      - run:
          name: Install Graphviz
          command: apt update && apt -y install graphviz
      - run:
          name: Install deps
          command: |
            pip install --no-cache-dir -r docs/requirements.txt
            pip install --no-cache-dir "setuptools ~= 42.0" "setuptools_scm[toml] >= 3.4"
            python setup.py --version
      - run:
          name: Build only this commit
          command: make -C docs SPHINXOPTS="-W" BUILDDIR="_build/no_version_html" html
      - store_artifacts:
          path: ./docs/_build/no_version_html/html
          destination: noversion
      - run:
          name: Stop or generate versioned docs?
          command: |
            set +e
            force_versioned="$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[docs?[ _]?versions?\]' )"
            set -e
            if [[ "x${CIRCLE_TAG}" = "x" && "${CIRCLE_BRANCH}" != "master" && "x${force_versioned}" = "x" ]]; then
              echo "Not a tag or master branch - skipping versioned docs."
              circleci step halt
            fi
      - run:
          name: Clean-up nonversioned docs.
          command: make -C docs clean
      - restore_cache:
          keys:
            - docs-v2-{{ .Branch }}-{{ .Revision }}
            - docs-v2-{{ .Branch }}-
            - docs-v2-master
            - docs-v2-
          paths:
            - ./docs/_build
      - run:
          name: Generate Versioned Docs
          command: make -f ./docs/Makefile versioned CURBRANCH=${CIRCLE_TAG:-$CIRCLE_BRANCH}
      - save_cache:
          key: docs-v2-{{ .Branch }}-{{ .Revision }}
          paths:
            - ./docs/_build
      - persist_to_workspace:
          root: docs/_build
          paths: html
      - store_artifacts:
          path: ./docs/_build/html/html
          destination: versioned

  deploy_docker:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/src/
    steps:
      - restore_cache:
          keys:
            - build-v2-{{ .Branch }}-{{ epoch }}
            - build-v2-{{ .Branch }}-
            - build-v2-master-
            - build-v2-
          paths:
            - /tmp/docker
      - run:
          name: Set-up a Docker registry
          command: |
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images from local registry
          command: |
            docker pull localhost:5000/sdcflows
            docker tag localhost:5000/sdcflows nipreps/sdcflows:latest
      - run:
          name: Deploy to Docker Hub
          no_output_timeout: 40m
          command: |
            if [[ -n "$DOCKER_PASS" ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PASS
              docker push nipreps/sdcflows:latest
              docker tag nipreps/sdcflows nipreps/sdcflows:$CIRCLE_TAG
              docker push nipreps/sdcflows:$CIRCLE_TAG
            fi

  test_package:
    docker:
      - image: circleci/python:3.7.4
    working_directory: /tmp/src/sdcflows
    steps:
      - checkout
      - run:
          name: Prepare environment & build
          command: |
            python3 -m venv /tmp/buildenv
            source /tmp/buildenv/bin/activate
            python3 -m pip install "setuptools ~= 42.0" wheel "setuptools_scm[toml] >= 3.4" \
                "pip>=10.0.1" twine docutils
            python setup.py sdist bdist_wheel
            twine check dist/sdcflows*
      - store_artifacts:
          path: /tmp/src/sdcflows/dist
      - persist_to_workspace:
          root: /tmp/src/sdcflows
          paths: dist
      - run:
          name: Install on separate environment and check version [sdist]
          command: |
            python3 -m venv /tmp/install_sdist
            source /tmp/install_sdist/bin/activate
            python3 -m pip install "setuptools ~= 42.0" "pip>=10.0.1"
            THISVERSION=$( python3 setup.py --version )
            THISVERSION=${CIRCLE_TAG:-$THISVERSION}
            python3 -m pip install dist/sdcflows*.tar.gz
            INSTALLED_VERSION=$(python3 -c 'import sdcflows as sdc; print(sdc.__version__, end="")')
            echo "VERSION: \"${THISVERSION}\""
            echo "INSTALLED: \"${INSTALLED_VERSION}\""
            test "${INSTALLED_VERSION}" = "${THISVERSION}"
      - run:
          name: Install on separate environment and check version [wheel]
          command: |
            python3 -m venv /tmp/install_wheel
            source /tmp/install_wheel/bin/activate
            python3 -m pip install "setuptools ~= 42.0" "pip>=10.0.1"
            THISVERSION=$( python3 setup.py --version )
            THISVERSION=${CIRCLE_TAG:-$THISVERSION}
            python3 -m pip install dist/sdcflows*.whl
            INSTALLED_VERSION=$(python3 -c 'import sdcflows as sdc; print(sdc.__version__, end="")')
            echo "VERSION: \"${THISVERSION}\""
            echo "INSTALLED: \"${INSTALLED_VERSION}\""
            test "${INSTALLED_VERSION}" = "${THISVERSION}"

  deploy_pypi:
    docker:
      - image: circleci/python:3.7.4
    working_directory: /tmp/src/sdcflows
    steps:
      - attach_workspace:
          at: /tmp/src/sdcflows
      - run:
          name: Upload to Pypi
          command: |
            python3 -m venv /tmp/upload
            source /tmp/upload/bin/activate
            python3 -m pip install twine
            python3 -m twine check dist/*
            python3 -m twine upload dist/* --non-interactive

  deploy_docs_tag:
    <<: *docs

  deploy_docs_master:
    <<: *docs

workflows:
  version: 2
  build_deploy:
    jobs:
      - cache_test_data:
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - build_n_pytest:
          requires:
            - cache_test_data
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - test_package:
          filters:
            branches:
              ignore:
                - /docs?\/.*/
                - /tests?\/.*/
            tags:
              only: /.*/

      - deploy_pypi:
          requires:
            - build_docs
            - test_package
            - build_n_pytest
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

      - deploy_docker:
          requires:
            - deploy_pypi
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

      - build_docs:
          filters:
            branches:
              ignore:
                - /tests?\/.*/
            tags:
              only: /.*/

      - deploy_docs_master:
          requires:
            - build_n_pytest
            - test_package
            - build_docs
          filters:
            branches:
              only: /master/
            tags:
              ignore: /.*/

      - deploy_docs_tag:
          requires:
            - deploy_docker
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
