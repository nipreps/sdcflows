version: 2
jobs:

  build:
    environment:
      - TZ: "/usr/share/zoneinfo/America/Los_Angeles"

    docker:
      - image: docker:18.01.0-ce-git
    working_directory: /tmp/src/
    steps:
      - run:
          name: Install parallel gzip and python3
          command: apk add --no-cache pigz python3
      - restore_cache:
          keys:
            - docker-v1-{{ .Branch }}-{{ epoch }}
            - docker-v1-{{ .Branch }}-
            - docker-v1-master-
            - docker-v1-
          paths:
            - /tmp/cache/docker.tar.gz

      - checkout
      - setup_remote_docker
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
            fi
            docker images
      - run:
          name: Build Docker image
          no_output_timeout: 60m
          command: |
            # Build docker image
            e=1 && for i in {1..5}; do
              docker build \
                --cache-from=poldracklab/sdcflows \
                --rm=false \
                -t poldracklab/sdcflows:latest \
                --build-arg BUILD_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ"` \
                --build-arg VCS_REF=`git rev-parse --short HEAD` \
                --build-arg VERSION="${CIRCLE_TAG:-unstable}" . \
              && e=0 && break || sleep 15
            done && [ "$e" -eq "0" ]
      - run:
          name: Docker save
          no_output_timeout: 40m
          command: |
            mkdir -p /tmp/cache
            docker save ubuntu:xenial-20161213 poldracklab/sdcflows:latest \
              | pigz -2 -p 3 > /tmp/cache/docker.tar.gz
      - persist_to_workspace:
          root: /tmp
          paths:
            - cache/docker.tar.gz

      - save_cache:
         key: docker-v1-{{ .Branch }}-{{ epoch }}
         paths:
            - /tmp/cache/docker.tar.gz

  cache_test_data:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/data
    steps:
      - restore_cache:
          keys:
            - data-v1-{{ .Branch }}-
            - data-v1-master-
            - data-v1-
      - run:
          name: Setup git-annex
          command: |
            mkdir -p /tmp/cache
            if [[ ! -e "/tmp/cache/git-annex-standalone.tar.gz" ]]; then
              wget -O- http://neuro.debian.net/lists/trusty.us-ca.full | sudo tee /etc/apt/sources.list.d/neurodebian.sources.list
              sudo apt-key adv --recv-keys --keyserver hkp://pool.sks-keyservers.net:80 0xA5D32F012649A5A9
              sudo apt update && sudo apt-get install -y --no-install-recommends git-annex-standalone
              mkdir -p /tmp/cache
              tar czvf /tmp/cache/git-annex-standalone.tar.gz /usr/bin/git-annex /usr/bin/git-annex-shell /usr/lib/git-annex.linux
            else
              sudo tar xzfv /tmp/cache/git-annex-standalone.tar.gz -C /
            fi
            git config --global user.name 'CRN'
            git config --global user.email 'crn.poldracklab@gmail.com'

      - run:
          name: Setup DataLad
          command: |
            pyenv global 3.5.2
            virtualenv venv
            pip install --no-cache-dir -U pip
            pip install --no-cache-dir -U datalad
      - run:
          name: Install ds001600
          command: |
            datalad install https://github.com/OpenNeuroDatasets/ds001600.git
            datalad update --merge ds001600/
            datalad get -r ds001600/*
      - run:
          name: Get testdata
          command: |
            if [[ ! -d /tmp/data/testdata ]]; then
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                  -O testdata.zip "https://files.osf.io/v1/resources/9sy2a/providers/osfstorage/5d44b940bcd6d900198ed6be/?zip="
              unzip testdata.zip -d /tmp/data/testdata
            fi

      - run:
          name: Store FreeSurfer license file
          command: |
            mkdir -p /tmp/data/
            echo "b2VzdGViYW5Ac3RhbmZvcmQuZWR1CjMwNzU2CiAqQ1MzYkJ5VXMxdTVNCiBGU2kvUGJsejJxR1V3Cg==" | base64 -d > /tmp/data/fslicense.txt

      - run:
          name: Create Nipype config files
          command: |
            printf "[execution]\nstop_on_first_crash = true\n" > /tmp/data/nipype.cfg
            echo "poll_sleep_duration = 0.01" >> /tmp/data/nipype.cfg
            echo "hash_method = content" >> /tmp/data/nipype.cfg
            echo "crashfile_format = txt" >> /tmp/data/nipype.cfg

      - save_cache:
         key: data-v1-{{ .Branch }}-{{ .BuildNum }}
         paths:
            - "/opt/circleci/.pyenv/versions/3.5.2"
            - /tmp/data
            - /tmp/cache/git-annex-standalone.tar.gz

      - persist_to_workspace:
          root: /tmp
          paths:
            - data

  test_sdcflows:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/tests
    steps:
      - attach_workspace:
          at: /tmp
      - checkout:
          path: /tmp/src/sdcflows
      - restore_cache:
          keys:
            - workdir-v1-{{ .Branch }}-
            - workdir-v1-master-
            - workdir-v1-
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              sudo apt update && sudo apt -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Run tests
          no_output_timeout: 2h
          command: |
            mkdir -p /tmp/work
            docker run -it --rm=false -e TEST_DATA_HOME=/data/ -e TEST_OUTPUT_DIR=/out \
                   -v /tmp/data/fslicense.txt:/opt/freesurfer/license.txt:ro -e FS_LICENSE=/opt/freesurfer/license.txt \
                   -v /tmp/work:/work -e TEST_WORK_DIR=/work \
                   -v /tmp/data/nipype.cfg:/home/sdcflows/.nipype/nipype.cfg \
                   -v /tmp/data:/data:ro -v /tmp/src:/src -v /tmp/tests:/out \
                   -w /work poldracklab/sdcflows:latest \
                   pytest -v --junit-xml=/out/pytest.xml /src/sdcflows/sdcflows

      - store_artifacts:
          path: /tmp/tests
      - store_artifacts:
          path: /tmp/work
      - store_test_results:
          path: /tmp/tests
      - save_cache:
         key: workdir-v1-{{ .Branch }}-{{ .BuildNum }}
         paths:
            - /tmp/work

  deploy_docker:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/src/
    steps:
      - attach_workspace:
          at: /tmp
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              sudo apt update && sudo apt -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Deploy to Docker Hub
          no_output_timeout: 40m
          command: |
            if [[ -n "$DOCKER_PASS" ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PASS
              docker push poldracklab/sdcflows:latest
              docker tag poldracklab/sdcflows poldracklab/sdcflows:$CIRCLE_TAG
              docker push poldracklab/sdcflows:$CIRCLE_TAG
            fi

  test_package:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/src/sdcflows
    steps:
      - checkout
      - run:
          name: Setup Python environment with virtualenvs
          command: |
            pyenv global 3.5.2
            python3 -m pip install --upgrade virtualenv
      - run:
          name: Prepare build environment
          command: |
            virtualenv --python=python3 /tmp/build
            source /tmp/build/bin/activate
            python3 -m pip install "setuptools>=30.3.0" "pip>=10.0.1" twine docutils
      - run:
          name: Prepare install environment
          command: |
            virtualenv --python=python3 /tmp/install
            source /tmp/install/bin/activate
            python3 -m pip install "setuptools>=30.3.0" "pip>=10.0.1"
      - run:
          name: Build SDCflows in build environment
          command: |
            source /tmp/build/bin/activate
            python setup.py sdist
      - store_artifacts:
          path: /tmp/src/sdcflows/dist
      - run:
          name: Check sdist package in build environment
          command: |
            source /tmp/build/bin/activate
            twine check dist/sdcflows*.tar.gz
      - run:
          name: Install sdist package into install environment and check version
          command: |
            source /tmp/install/bin/activate
            THISVERSION=$( python get_version.py )
            THISVERSION=${CIRCLE_TAG:-$THISVERSION}
            pip install dist/sdcflows*.tar.gz
            which sdcflows | grep install\\/bin
            INSTALLED_VERSION=$(sdcflows --version)
            INSTALLED_VERSION=${INSTALLED_VERSION%$'\r'}
            INSTALLED_VERSION=${INSTALLED_VERSION#*"sdcflows v"}
            echo "VERSION: \"$THISVERSION\""
            echo "INSTALLED: \"$INSTALLED_VERSION\""
            test "$INSTALLED_VERSION" = "v$THISVERSION"

  deploy_pypi:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/src/sdcflows
    steps:
      - checkout
      - run:
          name: Setup Python environment with virtualenvs
          command: |
            pyenv global 3.5.2
            python3 -m pip install --upgrade virtualenv
      - run:
          name: Prepare build environment
          command: |
            virtualenv --python=python3 /tmp/build
            source /tmp/build/bin/activate
            python3 -m pip install "setuptools>=30.3.0" "pip>=10.0.1" twine docutils
      - run:
          name: Prepare install environment
          command: |
            virtualenv --python=python3 /tmp/install
            source /tmp/install/bin/activate
            python3 -m pip install "setuptools>=30.3.0" "pip>=10.0.1"
      - run:
          name: Build SDCflows in build environment
          command: |
            source /tmp/build/bin/activate
            python setup.py sdist
      - store_artifacts:
          path: /tmp/src/sdcflows/dist
      - run:
          name: Check sdist package in build environment
          command: |
            source /tmp/build/bin/activate
            twine check dist/sdcflows*.tar.gz
      - run:
          name: Install sdist package into install environment and check version
          command: |
            source /tmp/install/bin/activate
            THISVERSION=$( python get_version.py )
            THISVERSION=${CIRCLE_TAG:-$THISVERSION}
            pip install dist/sdcflows*.tar.gz
            which sdcflows | grep install\\/bin
            INSTALLED_VERSION=$(sdcflows --version)
            INSTALLED_VERSION=${INSTALLED_VERSION%$'\r'}
            INSTALLED_VERSION=${INSTALLED_VERSION#*"sdcflows v"}
            echo "VERSION: \"$THISVERSION\""
            echo "INSTALLED: \"$INSTALLED_VERSION\""
            test "$INSTALLED_VERSION" = "v$THISVERSION"
      - run:
          name: Upload packages to PyPI
          command: |
            source /tmp/build/bin/activate
            twine upload dist/sdcflows*

workflows:
  version: 2
  build_deploy:
    jobs:
      - build:
          filters:
            tags:
              only: /.*/
      - cache_test_data:
          filters:
            tags:
              only: /.*/

      - test_sdcflows:
          requires:
            - build
            - cache_test_data
          filters:
            tags:
              only: /.*/


      - test_package:
          filters:
            tags:
              only: /.*/

      - deploy_pypi:
          requires:
            - build
            - test_package
            - test_sdcflows
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

      - deploy_docker:
          requires:
            - build
            - deploy_pypi
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
