name: CI

on:
  push:
  pull_request:
  schedule:
    - cron: 0 0 * * 0

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

defaults:
  run:
    shell: bash -el {0}

jobs:
  build-linux:
    if: "!contains(github.event.head_commit.message, '[skip ci]' && (github.event_name == 'push' || github.event.pull_request.head.repo.full_name != 'nipreps/sdcflows'))"
    runs-on: ubuntu-latest
    env:
      TEST_DATA_HOME: /home/runner/sdcflows-tests
      FSLOUTPUTTYPE: NIFTI_GZ
      FSLMULTIFILEQUIT: TRUE
      AFNI_HOME: /opt/afni
      AFNI_MODELPATH: /opt/afni/models
      AFNI_IMSAVE_WARNINGS: NO
      AFNI_TTATLAS_DATASET: /opt/afni/atlases
      AFNI_PLUGINPATH: /opt/afni/plugins
      ANTSPATH: /opt/ants
    strategy:
      max-parallel: 5
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]

    steps:
    - uses: actions/cache@v4
      with:
        path: /var/lib/apt
        key: apt-cache-v3
        restore-keys: |
          apt-cache-v3
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y --no-install-recommends \
                        curl bzip2 ca-certificates        \
                        tcsh gsl-bin netpbm               \
                        libjpeg62 xvfb xterm              \
                        libglu1-mesa-dev libglw1-mesa     \
                        libxm4 build-essential

    - uses: actions/cache@v4
      with:
        path: /opt/afni
        key: afni-v1
        restore-keys: |
          afni-v1
    - name: Install AFNI
      run: |
        if [[ ! -d "${AFNI_HOME}" ]]; then
          curl -O https://afni.nimh.nih.gov/pub/dist/bin/misc/@update.afni.binaries && \
          tcsh @update.afni.binaries -package linux_ubuntu_16_64 -bindir ${AFNI_HOME}
        fi

    - uses: actions/cache@v4
      with:
        path: /opt/ants
        key: ants-v1
        restore-keys: |
          ants-v1
    - name: Install ANTS
      run: |
        if [[ ! -d "${ANTSPATH}" ]]; then
          sudo mkdir -p $ANTSPATH
          curl -sSL "https://dl.dropbox.com/s/gwf51ykkk5bifyj/ants-Linux-centos6_x86_64-v2.3.4.tar.gz" | sudo tar -xzC $ANTSPATH --strip-components 1
        fi

    - name: Git settings (pacify DataLad)
      run: |
        git config --global user.name 'NiPreps Bot'
        git config --global user.email 'nipreps@gmail.com'
    - name: Set up Python ${{ matrix.python-version }}
      uses: conda-incubator/setup-miniconda@v3
      with:
        auto-update-conda: true
        auto-activate-base: true
        python-version: ${{ matrix.python-version }}
        channels: anaconda,https://fsl.fmrib.ox.ac.uk/fsldownloads/fslconda/public/,conda-forge
    - uses: actions/cache@v4
      id: conda
      env:
        CACHE_NUM: v4
      with:
        path: |
          ~/conda_pkgs_dir
          /home/runner/.cache/pip
        key: python-${{ matrix.python-version }}-${{ env.CACHE_NUM }}
        restore-keys: |
          python-${{ matrix.python-version }}-${{ env.CACHE_NUM }}
    - name: Install DataLad
      run: |
        conda install git-annex=*=alldep* pip
        pip install datalad datalad-osf
    - name: Install fsl
      run: |
        conda install fsl-fugue fsl-topup
    - uses: actions/checkout@v4
    - name: Install dependencies
      timeout-minutes: 5
      run: |
        pip install .[tests]


    - uses: actions/cache@v4
      with:
        path: ~/.cache/templateflow
        key: tf-cache-v1
        restore-keys: |
          tf-cache-
    - name: Get TemplateFlow's required objects
      run: |
        python tools/cache_templateflow.py

    - uses: actions/cache@v4
      with:
        path: ${{ env.TEST_DATA_HOME }}
        key: data-cache-v1
        restore-keys: |
          data-cache-
    - name: Install test data
      run: |
        mkdir -p ${{ env.TEST_DATA_HOME }}
        cd ${{ env.TEST_DATA_HOME }}

        # ds001600
        datalad install -r https://github.com/nipreps-data/ds001600.git
        datalad update -r --merge -d ds001600/
        datalad get -r -d ds001600/ ds001600/sub-1/

        # HCP/sub-101006
        datalad install -r https://github.com/nipreps-data/HCP101006.git
        datalad update -r --merge -d HCP101006/
        datalad get -r -d HCP101006

        # ds001771
        datalad install -r https://github.com/nipreps-data/ds001771.git
        datalad update -r --merge -d ds001771/
        datalad get -r -d ds001771/ ds001771/sub-36/*
        datalad get -r -d ds001771/derivatives ds001771/derivatives/openneuro/sub-36/*

        # ds000054
        datalad install -r https://github.com/nipreps-data/ds000054.git
        datalad update --merge -d ds000054/
        datalad get -r -d ds000054/ ds000054/sub-100185/*

        # ds000206
        datalad install -r https://github.com/nipreps-data/ds000206.git
        datalad update -r --merge -d ds000206/
        datalad get -r -d ds000206/ ds000206/sub-05/

    - name: Install FreeSurfer's mri_robust_template
      env:
        MRI_ROBUST_TEMPLATE: sx2n7/providers/osfstorage/5e825301d0e35400ebb481f2
      run: |
        curl https://files.osf.io/v1/resources/$MRI_ROBUST_TEMPLATE?direct > mri_robust_template
        sudo install mri_robust_template /usr/local/bin
        mkdir -p $HOME/.cache/freesurfer/
        echo "b2VzdGViYW5Ac3RhbmZvcmQuZWR1CjMwNzU2CiAqQ1MzYkJ5VXMxdTVNCiBGU2kvUGJsejJxR1V3Cg==" | base64 -d > $HOME/.cache/freesurfer/license.txt

    - name: Run pytest with coverage
      run: |
        export LD_LIBRARY_PATH=/usr/lib/fsl/5.0:$LD_LIBRARY_PATH
        export PATH=$ANTSPATH:${AFNI_HOME}:/usr/lib/fsl/5.0:$PATH
        pytest -v --cov sdcflows --cov-report xml:cov.xml --doctest-modules -n auto sdcflows

    - uses: codecov/codecov-action@v4
      with:
        file: cov.xml
        token: ${{ secrets.CODECOV_TOKEN }}
      if: ${{ always() }}
